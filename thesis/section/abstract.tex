\noindent In a relatively short period of time, the Internet has an amazing impact on almost every facet of our lives. With it, we are able to access new ideas, more information, unlimited possibilities, and a whole new world of communities. In addition, the demand for more and richer content has increased. To fulfill this demand, the Internet has evolved immensely in the last decade. Content become the king. Websites are becoming very rich in content as well as delivering high quality content to their customers. On top of it, introduction of social networking platforms such as Facebook, Twitter; video sharing sites such as Youtube has changed the user interaction with Internet by enabling them to publish their own content and share with each other which led to an exponential growth of Internet traffic. \\

\noindent To adopt this new trend, some companies are following state-of-the-art strategies for distributing their content while offering the best user experience. They have been deploying a large number of scalable and cost effective hosting infrastructure all around the globe. These hosting infrastructure can be composed of a few large data centers, a large number of caches or any combination. Some of these hosting companies handle a major chunk of web traffic, making them the hyper giants of today's Internet. Other websites use the infrastructure of these hyper giants to deliver their content. Such a scenario causes a large amount of traffic to flow through hyper giants, thus creating a huge dependency on them. Hence this thesis focuses on trying to answer the following questions, firstly, whether there any presence of these hyper giants in today's Internet? Secondly, what web objects contained in popular websites are delivered through hyper giants. Finding answers to these research questions help not only to other content distributing companies, content producers, content providers, and ISPs, but also to the research community at large. \\

\noindent In order to conduct this study, 100,000 top ranked websites of Alexa are used. DNS resolution is carried out on all these 100,000 websites along with their embedded links to analyze their second level domains that helps in determining the hosting infrastructure they use. HTTP header analysis is performed on these URLs that helps in finding out the reliance on hyper giants. The experimental results are supported by extensive analysis of data collected from a single vantage point in Germany. The results revealed that there are 26 hyper giants which are collectively contributing to almost 30\% percentage of total web traffic on Internet. It is found out that all the hyper giants put together deliver more number of text/HTML files than any other object type.



