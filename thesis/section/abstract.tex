In a relatively short period of time, the Internet has an amazing impact on almost every facet of our lives. With it, we are able to access new ideas, more information, unlimited possibilities, and a whole new world of communities. In addition, the demand for more and richer content has increased. To fulfill this demand, the Internet has evolved immensely in the last decade. Content become the king. Websites are becoming very rich in content as well as delivering high quality content to their customers. On top, introduction of social networking platforms such as Facebook, Twitter; video sharing sites such as Youtube has changed the user interaction with Internet by enabling them to publish their own content and share with each other which led to an exponential growth of Internet traffic. 

To adopt this new trend, some companies are following state-of-the-art strategies for distributing their content while offering the best user experience. They have been deploying a large number of scalable and cost effective hosting infrastructure all around the globe. These hosting infrastructure can be composed of a few large data centers ,a large number of caches or any combination. Some of these hosting companies handle a major chunk of web traffic, making them the hyper giants of today's Internet. Other websites use the infrastructure of these hyper giants to deliver their content. Such a scenario causes a large amount of traffic to flow through hyper giants, thus creating a huge dependency between them and other websites.

This thesis addresses some of the common research questions to study how these websites rely on hyper giants. Firstly, whether there any presence of these hyper giants in today's Internet? Secondly, how the dependency of websites on hyper giants is evolving with time. Finding answers to these research questions help not only to other content distributing companies, content producers, content providers, and ISPs, but also to the research community at large. 

In order to conduct this study, 100,000 top ranked websites of Alexa are used. DNS resolution is carried out on all these 100,000 websites along with their embedded links to analyze their second level domains that helps in determining the hosting infrastructure they use. HTTP header analysis is performed on these URLs that helps in finding out the reliance on hyper giants. The experimental results are supported by extensive analysis of data collected from a single vantage point in Germany. The results revealed that there are 26 hyper giants which are collectively contributing  xyz percenatge of total web traffic on Internet. ////Put results for web objects



